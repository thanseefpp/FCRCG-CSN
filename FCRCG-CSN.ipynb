{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python matplotlib tensorflow-macos\n",
    "\n",
    "#tensorflow~=2.6.0 and tensorflow-gpu==2.6.0 for non mac users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "# tensorflow functional apis\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input & Output Model Look Like\n",
    "#Model(input=[inputimgage, verificationImage], output=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU GROWTH (LIMIT GPU)\n",
    "##### DON'T USE THIS COMMAND IF YOU DON'T HAVE GPU ON YOUR DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folder Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying folder path\n",
    "POSITIVE_PATH = os.path.join('data','positive')\n",
    "NEGATIVE_PATH = os.path.join('data','negative')\n",
    "ANCHOR_PATH = os.path.join('data','anchor')\n",
    "# creating the folders\n",
    "# os.makedirs(POSITIVE_PATH)\n",
    "# os.makedirs(NEGATIVE_PATH)\n",
    "# os.makedirs(ANCHOR_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Dataset (Positive and Anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompress Tar GZ file\n",
    "# !tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Images to Data/Negative \n",
    "# for dir in os.listdir('lfw'):\n",
    "#     # to get the inside folder paths\n",
    "#     for file in os.listdir(os.path.join('lfw',dir)):\n",
    "#         exact_path = os.path.join('lfw',dir,file)\n",
    "#         new_path = os.path.join(NEGATIVE_PATH,file)\n",
    "#         os.replace(exact_path,new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf lfw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Positive and Anchor Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VideoCapture CV2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Cutting down frame to 250x250 px (last we have used (:) for getting all the colors)\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    \n",
    "    # Collect anchors\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        # Create a Unique file Path\n",
    "        img_name = os.path.join(ANCHOR_PATH,f\"{uuid.uuid1()}.jpg\")\n",
    "        # write image to anchor folder\n",
    "        cv2.imwrite(img_name,frame)\n",
    "    \n",
    "    # Collect Positive\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        # Create a Unique file Path\n",
    "        img_name = os.path.join(POSITIVE_PATH,f\"{uuid.uuid1()}.jpg\")\n",
    "        # Write image to positive folder\n",
    "        cv2.imwrite(img_name,frame)\n",
    "    \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press Q on keyboard to stop recording\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyWindow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshow(frame)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "08aacbd0cfbfa91a20a5a36773cab11d600e20bb1c2a36d6f38e139530d1d2e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
